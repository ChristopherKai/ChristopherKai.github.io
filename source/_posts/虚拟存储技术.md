---
title: 虚拟存储技术
tags: 
  -操作系统
  -笔记
grammar_emoji: true
---

# 虚拟内存

### 虚拟内存解决的问题：
原有的内存管理方式需要把整个程序加载到内存空间，如果只将程序的一部分加载到内存空间，有着以下优势：

1.程序大小不再决定于物理内存大小，计算机可以运行大于物理内存的程序
2.计算机可以运行的程序增加，提示cpu利用率，吞吐量
3.更少的置换I/O，不需swap in/out

### 虚拟内存的前提：
1.程序的错误处理部分不会经常发生，可以开始不加载
2.数组等数据结构分配的内存空间大于实际使用的内存空间
3.程序的特定功能很少被使用。比如美国政府电脑上平衡财政预算的程序部分。


## demand paging 
Concept:To load pages only as they are needed.

demand paging 引发诸多架构困难。

### 等效访问时间：
effective access time = (1 − p) × ma + p × page fault time.
p be the probability of a page fault (0 ≤ p ≤ 1)
the memory-access time, denoted ma


### Page Fault 服务程序
    1. Service the page-fault interrupt. 
    2. Read in the page. 
    3. Restart the process.

硬盘上的置换分区（swap space）由于特殊的结构，访问速度比文件系统更快。

### demand paging请求调页实现方法
    1.加载进程前，将整个程序加载到置换分区，然后demand paging
    2.将程序从文件系统按需加载，当页面被置换的时候，将页面写入置换分区。这种方法保证了只有所需的页面从文件系统加载，后续的paging从置换分区进行。
    3.需求页面从文件系统加载，当页面置换时，原有页面会被覆盖（因为是纯代码，需求时可从文件系统加载），置换分区主要负责heap，stack等内存页面（被称作匿名内存）。备用于Solaris和BSD Linux。

移动设备操作系统不支持换页swapping，当需求页面时，直接从文件系统加载。当内存不足时，直接回收只读纯代码页面。
在iOS下，匿名内存页面永不回收，除非应用被终止或明确释放内存。

总结，方法3类似移动设备的解决方案，都从文件系统加载，内存不足都会直接覆盖页面，该页面再需求时，再从文件系统加载。区别于，方法3会将匿名内存swap到置换分区上，移动设备则几乎永远保留。


#### Note.
fork()创建新进程可以不需要demand paging，直接page sharing即可。



## Copy-on-Write(COW)
指定特定物理页面为copy-on-wirte(仅可修改页面)，当进程需要写入该页面时候(on write)，复制一份(copy)。

fork()的时候，新进程指向和原进程相同的物理页面，只不过部分页面指定为copy-on-write。当新进程需要写入操作，比如增加stack，heap等，由操作系统从frea pages pool寻找空闲页面，进行zero-fill-on-demand，用0填充。

fork()基于copy-on-write实现，而 vfork()则不使用copy-on-write技术，此方法下，父进程会暂停，子进程继承父进程的地址空间，子进程对地址空间的修改将会在父进程恢复后可见。vfork()常用于子进程须立即调用exec()的情况。在没有COW技术以前，fork()成本很高，需要完全复制新的地址空间，所以在fork()后使用exec丢弃原有地址空间，加载新地址空间是种浪费，所以设计了vfork()，和父进程共享地址空间，执行exec后使用新的地址空间，提高效率。当有COW技术后，vfork()+exec()和fork() + exec()效率几乎一样。
[Difference Between fork() and vfork()][1]
[fork,vfork][2]


## 页面置换

在使用demand paging的时候虽然增加了系统同时执行多道程序能力，然而会造成内存的过分配(over-allocating)。当page fault发生，然而此时没有空闲页面的时候，就需要页面置换了。

当没有空闲页面时，page fault后可以选择
    1.中断该程序
    2.置换一整个进程
    3.置换一个页面到置换分区 page replacement


### 新的page fault 服务程序
1. Find the location of the desired page on the disk.
2. Find a free frame:
    a. If there is a free frame, use it.
    b. If there is no free frame, use a page-replacement algorithm to select a victim frame.
    c. Write the victim frame to the disk; change the page and frame tables accordingly.
3. Read the desired page into the newly freed frame; change the page and
frame tables.
4. Continue the user process from where the page fault occurred.

Note.
在没有空闲页面的时候，需要将1张待用的页面置换入内存，1张暂时不用的页面置换到置换分区。这样就降低了服务程序的效率。所以在页表上应当设置dirty bit(modify bit)，指明该页面自从从文件系统加载到内存有无修改。如果无修改，则无需将该页面置换到置换分区，直接将其用新的待加载页面覆盖即可，提升了效率。


### demand paging 的2大核心算法

1.  frame-allocation algorithm 页面分配算法
2.  page-replacement algorithm 页面置换算法


page-replacement algorithm 物理页面分配算法主要解决，当加载一个进程的时候，到底给其分配多少物理内存页面的问题。

page-replacement algorithm 页面置换算法主要解决如何选择置换页面的问题。算法好的标准，低的page fault rate。

**置换算法分类：**
*   局部置换算法，只置换本进程的物理页面。进程分配页面数不会改变。
*   全局置换算法，会跨进程置换物理页面。页面数会变化。缺点：无法控制自己的page fault rate。

局部置换算法

1.  最优置换算法(OPT)：理想化，不可实现，在时间轴上向前看，将未来最久才会被访问的页面置换出去
2.  最近最久未使用算法(LRU)：难实现，在时间轴上向后看，根据之前对也页面的访问统计进行置换，least recently used的页面会被置换
3.  FIFO，根据加载到内存的顺序进行置换
4.  clock，时钟置换算法，即在FIFO基础上，将页表内设置访问位，页面置换时，从前往后，只置换未访问页面，如果扫描中发现某页为已访问，则置为未访问状态，重新计时，并跳到下一页查找置换页。如同时钟一样扫描环形链表。又叫二次机会页面置换算法
5.  LFU，最不常用页面置换算法
6.  MFU，最常用页面置换算法，基于刚置入内存的页面访问频率很低的论据。

##### LRU

实现方法：
1.  counters计数器 在页表内设置记载访问时间的位，当内存访问时，将当前时钟寄存器内容复制到
    page table记载位。这种方法需要搜索页表查找置换页，以及每次访问内存都得写内存。
2.  Stack。越往上越最近使用。每次内存访问，将访问页置顶，需要置换时，将stack底部页面置换。

![stack实现的LRU置换算法][3]

Note.
Belady现象
![belady现象][4]
随着物理内存增加，page fault rate增加。LRU，OPT等stack算法不会出现这种现象。 the set of pages in memory for n
frames is always a subset of the set of pages that would be in memory with n + 1 frames.即物理内存增大1页，原有的内存页面集合是增大后的内存页面集合的子集。

**额外引用位算法**

每次内存访问，引用位置1。页表内设置8比特的访问记录。每隔一段时间，访问记录右移一位，将引用位移到访问记录到最高位上，丢弃原有最低位。
这样00000000表示8个时间间隔内未访问该页，11111111表示每个时间间隔都访问了该页，11001100比起00110011更最近使用。如果将该记录解释为无符号整数，数字最小的将会是LRU页面，可以置换。

这些访问记录位的数量可以改变，如果变为0，也就是**二次机会页面置换算法**aka clock算法

**增强的clock算法**考虑了修改位，这种算法减少了修改页的处理开销，尽量避免置换修改页。





#### 页面缓冲算法

1.先加载页面到空闲物理内存，再置换victim物理页面到外存，并加入free frames pool，加速了进程重启速度。
2.周期性将修改过的页面写入置换分区，这样page fault适合，页面大概率时干净的，无需再次写入外存。
3.free-frame buffer ？？？
4.freaa-frame buffer pool:始终保留一定的空闲页面池，进程需要则分配，随后在进行页面置换，保持空闲页面池。

#### 应用与页面置换

有些情况下，应用通过虚拟内存访问数据的性能比没有的时候更差。比如数据库。
比如，数据仓库读取大量数据，然后计算后写入磁盘。LRU会保留新页面，然而应用更倾向于先使用旧的页面的数据进行计算。
因此，操作系统提供了raw disk和raw IO，绕过了文件系统。


**最小页面数**
进程最小页面数由系统架构(ISA)决定。具体来说，最小页面数由一条指令可能引用的页面数决定。如果不包含间接定址，只需要2个页面即可，1个指令页面，1个操作数页面。如果一条指令由于多次间接引用，需要访问不同页面，在到达执行步骤前未能将所需操作数取到，将会不断page fault，无法执行，最终需要分配不小于该条指令引用的页面数，即最小页面数。


### 页面分配算法

平均分配未考虑进程特性，会造成内存浪费。
按比例分配：按单个进程所需页面数与所有进程所需页面数的比例分配页面。需要大内存的进程分得更多页面。


**NUMA非均匀内存访问**
由于主板，cpu，内存的布局结构问题，cpu访问不同的内存位置，访问时间会不同。
分配算法的修改思路：随着调度器将进程调度到某个cpu上，对应地分配内存时，应将内存分配到和cpu同一块system board的内存部分上。

**Thrashing**
由于内存不足，一个进程的换页时间大于其执行时间。
![Thranshing][5]

原因：一个进程内存不够page fault的时候，使用*全局置换算法*，将其他进程的页面置换到外存，然而置换出去的页面也是对应进程需要的。被置换页面的进程由于所需页面被置换，page fault继续倾吞其他进程的页面，最终导致所有进程互相倾吞对方的内存页面，不断的页面置换，进程全部暂停，处于等待磁盘IO的状态，CPU误以为利用率低，继续产生进程，提升多道程序能力，加剧这种现象，事实是CPU利用率更低。

解决办法：先考虑使用局部置换算法，这样，一个进程thrash了，无法窃取其他进程内存，无法造成其他进程的thrash。这样保证其他进程不会被影响。但是该进程处于始终等待paging device的状态，page fault的服务时间增加，影响了别的进程的EAT（等效访问时间）。想要彻底解决该问题，就需要保证分配给进程足够的页面数。

如何确定进程所需的页面数：
1.工作集策略。此方法定义了进程的局部性模型。局部性模型指进程运行时，从一个部分运行到另外一个部分。当不满足当前局部性时，会一直page fault，直到所有所需页面加载完毕，在转移局部性时，再次page fault，直到再次满足局部性。


**工作集模型**
工作集窗口：delta，最近的delta次页面访问
工作集：最近的delta次页面访问的页面集合，可以近似进程的局部性

关键：确定delta的大小，使得工作集体现进程的局部性。

**工作集置换算法**

假定delta为工作集窗口，delta次访问过页面即为工作集，在每次访问的时候，换出不在工作集页面，缺页则直接置入页面。

思想，每次访存剔除不在工作集页面，缺页则将页面置入。

**缺页率置换算法**

缺页率：缺页次数/访存次数，或者缺页时间间隔的倒数。

两次缺页间隔 > 某一阈值 ，置换这两次间隔内未被引用的页面。
两次缺页间隔 <= 某一阈值，将所缺页面加入常驻集。

思想：在缺页时根据缺页时间间隔改变常驻集以适应工作集。

**Memory-mapped Files**

//TODO

**Memory-mapped IO**

//TODO

**内核内存分配**

为了避免页式内存管理造成的碎片，以及特定硬件需要连续内存，内核内存分配使用连续分配算法。

    1.伙伴系统内存分配 Buddy system
    2.Slab内存分配，Slub，Slob内存分配
    
    
### **__其他__**

**预先调页 prepaging**

避免纯粹调页下，进程启动时的大量page faults。在暂停进程时，讲进程的工作集记录，再次启动时，先将工作集调入内存。

**页面大小 page size**

//

**TLR reach**

//

**反置页表与请求调页**

//

**程序结构**

```c
    int i, j;
    int[128][128] data;
    for (i = 0; i < 128; i++)
    for (j = 0; j < 128; j++)
    data[i][j] = 0;
```

虽然虚拟内存对程序透明，但是应当尽量提升程序的局部性，减少page faults。


**I/O Interlock and Page Locking**

页面锁为了防止出现以下情况：
一个进程请求IO，等待IO数据加载到内存缓冲页面。CPU调度到了其他进程。其他进程发生page fault，而且使用全局置换算法，置换了等待进程的缓冲页面。等到IO请求完成时，数据覆盖了该进程。

解决方案：
1.避免将IO写入用户内存。IO只发生在内核内存和IO设备间。  （X 复制开销太大）
2.在内存页面设置lock位，在IO期间，lock位置位。页面置换算法则会不去置换锁定(lock)的页面。

此外，内核常将自身内存锁定。某些应用程序，如数据库对自身内存使用情况更为了解，会将内存锁定，避免置换。操作系统会提供相关syscall。

```c
POSIX
#include <sys/mman.h>

int mlock(const void *addr, size_t len);
int munlock(const void *addr, size_t len);

int mlockall(int flags);
int munlockall(void);


> mlock() and munlock() mlock() locks pages in the address range
> starting at addr and continuing  for  len  bytes. All pages that
> contain a part of the specified address range are guaranteed to be
> resident in RAM when the call returns successfully; the pages are
> guaranteed to stay in  RAM  until later unlocked.
> 
> munlock()  unlocks  pages  in  the  address  range starting at addr
> and continuing for len bytes.  After this call, all pages that contain
> a part of the specified memory  range  can be moved to external swap
> space again by the kernel.

WIN
BOOL WINAPI VirtualLock(
  _In_ LPVOID lpAddress,
  _In_ SIZE_T dwSize
);

```



内存页面的位：
1.reference bit 记录一段时间内的页面访问情况，统计工作集，用于页面置换算法。
2.modify bit 记录页面自从从外存加载到内存有无修改，若无，则在页面置换的时候无需换出，直接覆盖。
2.modify bit 记录页面自从从外存加载到内存有无修改，若无，则在页面置换的时候无需换出，直接覆盖。
3.lock bit 防止置换算法将页面换出。
4.presenece bit 存在位，是否存在对应frame，触发page fault，继而请求调页。


  [1]: https://techdifferences.com/difference-between-fork-and-vfork.html
  [2]: https://stackoverflow.com/questions/4856255/the-difference-between-fork-vfork-exec-and-clone
  [3]: https://www.github.com/ChristopherKai/picsRepo/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1517734351790.jpg
  [4]: https://www.github.com/ChristopherKai/picsRepo/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1517734814417.jpg
  [5]: https://www.github.com/ChristopherKai/picsRepo/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1517845412780.jpg
  [6]: https://www.github.com/ChristopherKai/picsRepo/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/1518519725753.jpg