---
title: 内存管理
tags:
  - 操作系统
  - 笔记
  - Operating system
  - Notes
grammar_emoji: true
---
# 内存管理

## 连续内存管理

*   固定大小：MFT
*   可变大小：MVT

*   策略： 

 **First fit**. Allocate the first hole that is big enough. Searching can start either at the beginning of the set of holes or at the location where the previous first-fit search ended. We can stop searching as soon as we find a free hole that is large enough. 

 **Best fit**. Allocate the smallest hole that is big enough. We must search the entire list, unless the list is ordered by size. This strategy produces the smallest leftover hole.

 **Worst fit**. Allocate the largest hole. Again, we must search the entire list, unless it is sorted by size. This strategy produces the largest leftover hole, which may be more useful than the smaller leftover hole from a best-fit approach.

 *评价*： both first fit and best fit are better than worst fit in terms of decreasing time and storage utilization. Neither first fit nor best fit is clearly better than the other in terms of storage utilization, but first fit is generally faster.

 三种策略都会产生碎片    内外相对于操作系统分配给进程的空间而言。

    1.外部碎片：系统分配的空间之间无法再分配给进程的内存空间   [processA 4k,,between 2KprocessB 5K]  wasted 2k,allocate minimal size 4K
    2.内部碎片：分配给进程的空间，但是比进程请求大小大的内存空间  [Allocated  10K,  process requeste 4k]    wasted 6k

对待碎片的办法：Compaction，移动进程空间合并空闲内存

compaction的可行性：Compaction is not always possible, however. If relocation is static and is done at assembly or load time, compaction cannot be done. It is possible only if relocation is dynamic and is done at execution time. If addresses are relocated dynamically, relocation requires only moving the program and data and then changing the base register to reflect the new base address.

compaction的实现方法：

    1.所有进程移动到内存一端
    2.使进程逻辑地址不连续：
        2.1.分段segmentation
        2.2.分页paging

## 非连续内存分配
### 分段Segmentation：

原理：程序员视角下，程序分为不同的段，如代码段，数据段，堆。。为了支持这种视角，内存分段。逻辑地址变为<segmentation number,offset>

C编译器会创建的段：
    1.The code
    2. Global variables
    3. The heap, from which memory is allocated
    4. The stacks used by each thread
    5. The standard C libraryLibraries that are linked in during compile time might be assigned separate segments. The loader would take all these segments and assign them segment numbers.
    加载器会给各个段分配段号。

### 分页Paging：

#### 优势：
可以避免外部碎片，避免compaction。而且解决了将可变大小内存块备份到back storage的问题，可以使可使用的物理地址范围大于cpu地址指针范围。

Note.
由于进程内存要换swap到back storage上时，由于back storage速度低，同时同样存在碎片，back  storage的compaction就不可行。


#### 方法：
分割内存为固定大小，称作frames；同时分割逻辑内存为同样大小，称作pages。back storage同样分割为同样大小，或该大小的整数倍。将pages根据page table映射到frame上。逻辑地址前一部分作为page table的索引，后一部分作为frame内的偏移。PTBR和PTLR(page-table length register )，PTLR指明page table的长度

Terms：
page table：
逻辑地址物理地址转换表
frame table：
表示物理内存上的frames 是否可用的表

对进程context switch 的影响：The operating system maintains a copy of the page table for each process, just as it maintains a copy of the instruction counter and register contents.A pointer to the page table is stored with the other register values (like the instruction counter) in the process control block.
每个进程创建一张页表，页表指针和其他寄存器值一同储存在进程控制单元（ process control block）内。


#### 页表具体实现：
    1.  DEC PDP-11：用寄存器来实现页表的架构。
    2.  当代架构：PTBR，a page-table base register指向页表，context switch时候只需改变ptbr即可，减少开销。  

 缺点：每次地址转换需要访问两次内存（内存取page number和访问物理地址）    

 解决方案：
 1.TLB，translation look-aside buffer，快表，逻辑地址page number作key，物理地址frame number作value的数组缓存，每次针对page number会与所有项目的key同时比较，所以快,有的会包含ASID信息，用于识别进程以及保护信息，如果没有ASIDs则context switch后，TLB会flush掉TLB以用新进程的page table.TLB的hit ratio 直接影响内存访问性能。



 page table内容：
 1.frame number
 2.valid 或者invliad 是否存在对应的frame，可能存在一个page被置为vaid但是进程实际空间小于page size，造成内部碎片。


 shared pages:
 可以将reentrant code跨进程共享。

 #### 页表的结构分类:

 1.hierarchical paging,多级页表aka forward-mapped page table     举例VAX
 2.hashed page tables,  变体clustered page tables（？） 举例
 3.inverted page tables.反置页表，页表项需包含ASIDs，变体哈希反置页表 ，如何解决共享内存的问题？？？？？


 分页具体实现：
 1.Oracle SPARC Solaris 64位，多级哈希页表，用户和内核相互独立的页表，每个页表项对应一片连续page，包含一个base和span number，指明page数目？？？？。。。。。。
 2.8086、8088支持分段，IA32支持分页分段

 具体
 **_IA32：_**
 CPU --> 逻辑地址  -->分段单元 --> 线性地址 -->分页单元 -->物理地址 --->内存

 分段：

 MMU 内存管理单元：分段单元，分页单元
 段大小可达4GB，每个进程段的数量16K，逻辑地址空间分为2部分，第一部分包含`! 2 **13 `(8K)个段，对进程私有，第二部分 8K段，跨进程共享。第一部分信息在LDT，第二部分在GDT。每个表项8字节，包含基址base和段界限limit。逻辑地址为  (selector, offset)selector为16位，13位 段号，1位指明是LDT还是GDT，2位保护。共有6个段寄存器，允许一个进程同时定址6个段。同时有6个8字节的描述符寄存器，保存gdt，ldt描述符。offset偏移加上selector指向的描述符基址，形成32位线性地址。

 分页：

 支持页大小4k或4M。对于4K使用2层分页机制,p1:10位，p2：10位，page offset：12位.p1:作为页目录page directory，cr3寄存器指向当前进程页目录页目录项包含Page_Size的flag表明是4kb还是4MB，如果为4MB，则p2和offset结合起来直接指向4MB的frame
 图例
 ![enter description here][1]
 PAE（page address extension）的引入：线性地址前两位作为page directory pointer table，
 ![enter description here][2]

 PAE允许访问的物理空间大于4GBPAE also increased the page-directory and page-table entries from 32 to 64 bits in size, which allowed the base address of page tables and page frames to extend from 20 to 24 bits. Combined with the 12-bit offset, adding PAE support to IA-32 increased the address space to 36 bits, which supports up to 64 GB of physical memory. It is important to note that operating system support is required to use PAE. Both Linux and Intel Mac OS X support PAE. However, 32-bit versions of Windows desktop operating systems still provide support for only 4 GB of physical memory, even if PAE is enabled.windows 又被黑了。

**_x86-64_**

**_历史_**

曾经研发IA64（后来的Itanium），但是未被广泛接受。同时AMD在IA32上拓展，研发了x86-64，结果intel学习了AMD的结构。

具体

48位的虚拟地址，页大小4kb，2MB，1GB，使用了4级页表，加上PAE的支持，空间达到52比特
![enter description here][3]


FROM BOOK OS Concepts:

Terminology:
1.input queue:The processes on the disk that are waiting to be brought into memory for execution form the input queue.    ready queue:The system maintains a ready queue consisting of all processes whose memory images are on the backing store or in memory and are ready to run.
2.逻辑地址：cpu生成的地址
3.物理地址：内存看到的地址，载入到内存地址寄存器的地址
4.虚拟地址：The compile-time and load-time address-binding methods generate identical logical and physical addresses。However, the execution-time address- binding scheme results in differing logical and physical addresses. In this case, we usually refer to the logical address as a virtual address.
5.MMU（memory-management unit）：实现逻辑地址到物理地址的转换
6.动态加载   只加载自用模块，只需os提供加载库
7.动态链接  加载跨进程共享库，需要os协助，因为需要跨进程内存访问
8.Swap ，移动操作系统不支持    {        Modified versions of swapping, however, are found on many systems, including UNIX, Linux, and Windows. In one common variation, swapping is normally disabled but will start if the amount of free memory (unused memory available for the operating system or processes to use) falls below a threshold amount. Swapping is halted when the amount of free memory increases. Another variation involves swapping portions of processes—rather than entire processes—to decrease swap time. Typically, these modified forms of swapping work in conjunction with virtual memory, which we cover in Chapter 9.    }
9.double buffering
10.50-percent rule.：Statistical analysis of first fit, for instance, reveals that, even with some optimization, given N allocated blocks, another 0.5 N blocks will be lost to fragmentation. That is, one-third of memory may be unusable! This property is known as the 50-percent rule.
11.wired down：TLB中无法被替换的项目，比如kernel地址
12.reentrant code:non-self-modifying code:,it never changes during execution.


地址绑定：将程序内指令与物理地址绑定绑定可以发生在：
1.编译时（编译时确定了运行时绝对地址）
2.加载时
3.运行时（If the process can be moved during its execution from one memory segment to another, then binding must be delayed until run time. Special hardware must be available for this scheme to work, as will be discussed in Section 8.1.3\. Most general-purpose operating systems use this method.）


  [1]: https://www.github.com/ChristopherKai/picsRepo/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/pic-1517647969601.png "pic-1517647969601"
  [2]: https://www.github.com/ChristopherKai/picsRepo/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/pic-1517647969623.png "pic-1517647969623"
  [3]: https://www.github.com/ChristopherKai/picsRepo/raw/master/%E5%B0%8F%E4%B9%A6%E5%8C%A0/pic-1517647969601.png "pic-1517647969601"
